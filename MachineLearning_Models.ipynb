{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaZAHe6Zzfsr",
        "outputId": "8320844f-3a5a-40bf-b0c8-7a3c892baab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9875\n",
            "Precision: 0.9938\n",
            "Recall: 0.9875\n",
            "F1 Score: 0.9875\n"
          ]
        }
      ],
      "source": [
        "#svm\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the CSV file\n",
        "file_path = \"/content/data.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['Type']\n",
        "\n",
        "# Normalize the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Define a fixed random state\n",
        "fixed_random_state = 357\n",
        "\n",
        "# Divide the dataset into training and test sets with fixed random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=fixed_random_state)\n",
        "\n",
        "# Initialize the SVM classifier (Class: sklearn.svm.SVC)\n",
        "svm_classifier = SVC(kernel='linear', C=1.0, probability=True)\n",
        "\n",
        "# Train the classifier\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the accuracy, precision, recall, and F1 score\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvlMw2XOzFex",
        "outputId": "af3eb424-06e8-4c9f-98fa-186c5c0da827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9931\n",
            "Precision: 0.9933\n",
            "Recall: 0.9931\n",
            "F1 Score: 0.9931\n"
          ]
        }
      ],
      "source": [
        "#svm with da\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the CSV file\n",
        "file_path = \"/content/augmented2.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['Type']\n",
        "\n",
        "# Normalize the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Define a fixed random state\n",
        "fixed_random_state = 600\n",
        "\n",
        "# Divide the dataset into training and test sets with fixed random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=fixed_random_state)\n",
        "\n",
        "# Initialize the SVM classifier (Class: sklearn.svm.SVC)\n",
        "svm_classifier = SVC(kernel='linear', C=1.0, probability=True)\n",
        "\n",
        "# Train the classifier\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the accuracy, precision, recall, and F1 score\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSZM03XG1TIz",
        "outputId": "29d24c81-01b3-4632-e8c7-053f54306215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n"
          ]
        }
      ],
      "source": [
        "#random forest with daa\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the CSV file\n",
        "file_path = \"/content/augmented2.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['Type']\n",
        "\n",
        "# Define a fixed random state\n",
        "fixed_random_state = 1\n",
        "\n",
        "# Split the dataset into training and testing sets with fixed random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=fixed_random_state)\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=fixed_random_state)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the accuracy, precision, recall, and F1 score\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKWXZVQ89GLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c608d29c-e8a3-4598-e49b-52f3b04128d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9625\n",
            "Precision: 0.9633\n",
            "Recall: 0.9625\n",
            "F1 Score: 0.9618\n"
          ]
        }
      ],
      "source": [
        "#random  forest\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the CSV file\n",
        "file_path = \"/content/data.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['Type']\n",
        "\n",
        "# Define a fixed random state\n",
        "fixed_random_state = 177\n",
        "\n",
        "# Split the dataset into training and testing sets with fixed random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=fixed_random_state)\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=fixed_random_state)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the accuracy, precision, recall, and F1 score\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#random  forest with daa\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the CSV file\n",
        "file_path = \"/content/augmented2.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['Type']\n",
        "\n",
        "# Define a fixed random state\n",
        "fixed_random_state = 265\n",
        "\n",
        "# Split the dataset into training and testing sets with fixed random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=fixed_random_state)\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=fixed_random_state)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the accuracy, precision, recall, and F1 score\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzZ6TN0_fDyn",
        "outputId": "74bb0383-3702-4eab-d7de-e1ac399eacb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9897\n",
            "Precision: 0.9901\n",
            "Recall: 0.9897\n",
            "F1 Score: 0.9896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbZ9Olrb9YM4",
        "outputId": "960f3223-b0f1-47ab-f654-d869ea8638e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9625\n",
            "Precision: 0.9650\n",
            "Recall: 0.9625\n",
            "F1 Score: 0.9598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [19] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        }
      ],
      "source": [
        "#DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Read the CSV file\n",
        "file_path = \"/content/data.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['Type']\n",
        "\n",
        "# Select the k best features\n",
        "k = 16  # Number of top features to select\n",
        "selector = SelectKBest(score_func=f_classif, k=k)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "# Define a fixed random state\n",
        "fixed_random_state = 414\n",
        "\n",
        "# Split the dataset into training and testing sets with fixed random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=fixed_random_state)\n",
        "\n",
        "# Create the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=fixed_random_state)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ3oVhjU-9qR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w8bLdY79IT6",
        "outputId": "7c2cc31b-34f8-45cf-af66-8b18089bd6c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9966\n",
            "Precision: 0.9967\n",
            "Recall: 0.9966\n",
            "F1 Score: 0.9966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [13 19] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        }
      ],
      "source": [
        "#DecisionTreeClassifier da\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Read the CSV file\n",
        "file_path = \"/content/augmented2.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['Type']\n",
        "\n",
        "# Select the k best features\n",
        "k = 16  # Number of top features to select\n",
        "selector = SelectKBest(score_func=f_classif, k=k)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "# Define a fixed random state\n",
        "fixed_random_state = 463\n",
        "\n",
        "# Split the dataset into training and testing sets with fixed random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=fixed_random_state)\n",
        "\n",
        "# Create the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=fixed_random_state)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1 score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjDWks3G_TUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e688868-dcbc-4dc6-e0f9-c176661e61e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 5ms/step\n",
            "Accuracy: 0.9\n"
          ]
        }
      ],
      "source": [
        "#multiroww dnn\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Read the CSV file\n",
        "file_path = \"/content/data.csv\"  # Replace with your actual file path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['Type']  # Replace 'Type' with your actual target column name\n",
        "\n",
        "# Convert target variable to numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# One-hot encode the target variable for multi-class classification\n",
        "y_one_hot = to_categorical(y_encoded)\n",
        "\n",
        "# Standardize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define a fixed random state\n",
        "fixed_random_state = 189\n",
        "\n",
        "# Split the dataset into training and test sets with fixed random state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_one_hot, test_size=0.2, random_state=fixed_random_state)\n",
        "\n",
        "# Define the DNN model\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(512, activation='relu'),  # First hidden layer\n",
        "    Dense(512, activation='relu'),  # Second hidden layer\n",
        "    Dense(y_one_hot.shape[1], activation='softmax')  # Output layer for multi-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=50, verbose=0)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = y_pred_prob.argmax(axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Convert one-hot encoded y_test back to original labels for comparison\n",
        "y_test_labels = y_test.argmax(axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_labels, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVUnTwDO_znJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63341159-0afb-4369-b68e-fb4482e7fed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            " Model Accuracy: 0.9759\n",
            " Model Precision: 0.9769\n",
            " Model Recall: 0.9759\n",
            " Model F1-score: 0.9757\n"
          ]
        }
      ],
      "source": [
        "#multiroww dnn\n",
        "#\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the CSV file\n",
        "file_path = \"/content/augmented2.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['Type']\n",
        "\n",
        "# Convert y to one-hot encoding if needed\n",
        "if len(y.shape) == 1 or y.shape[1] == 1:\n",
        "    y = pd.get_dummies(y)\n",
        "\n",
        "# Define multiple deep learning models\n",
        "def create_models(input_shape, output_shape):\n",
        "    models = []\n",
        "\n",
        "    # Model 1\n",
        "    model1 = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(input_shape,)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(output_shape, activation='softmax')\n",
        "    ])\n",
        "    model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    models.append(model1)\n",
        "\n",
        "    # Model 2\n",
        "    model2 = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(output_shape, activation='softmax')\n",
        "    ])\n",
        "    model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    models.append(model2)\n",
        "\n",
        "    # Model 3\n",
        "    model3 = Sequential([\n",
        "        Dense(256, activation='relu', input_shape=(input_shape,)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(output_shape, activation='softmax')\n",
        "    ])\n",
        "    model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    models.append(model3)\n",
        "\n",
        "    return models\n",
        "\n",
        "# Define a fixed random state\n",
        "fixed_random_state = 165\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=fixed_random_state)\n",
        "\n",
        "# Create models\n",
        "models = create_models(X.shape[1], y.shape[1])\n",
        "\n",
        "# Train each model\n",
        "for model in models:\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# Make predictions with each model\n",
        "predictions = [model.predict(X_test) for model in models]\n",
        "\n",
        "# Ensemble predictions by averaging\n",
        "ensemble_predictions = np.mean(predictions, axis=0)\n",
        "y_pred = np.argmax(ensemble_predictions, axis=1)\n",
        "\n",
        "# Evaluate ensemble model\n",
        "accuracy = accuracy_score(np.argmax(y_test.to_numpy(), axis=1), y_pred)\n",
        "precision = precision_score(np.argmax(y_test.to_numpy(), axis=1), y_pred, average='weighted')\n",
        "recall = recall_score(np.argmax(y_test.to_numpy(), axis=1), y_pred, average='weighted')\n",
        "f1 = f1_score(np.argmax(y_test.to_numpy(), axis=1), y_pred, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f' Model Accuracy: {accuracy:.4f}')\n",
        "print(f' Model Precision: {precision:.4f}')\n",
        "print(f' Model Recall: {recall:.4f}')\n",
        "print(f' Model F1-score: {f1:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaQtMWGRUNlG",
        "outputId": "674ce55f-91f5-4554-dd8e-bb4e462875b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'}\n",
            "Accuracy: 0.95\n",
            "Precision: 0.9622685185185185\n",
            "Recall: 0.95\n",
            "F1-score: 0.9477446483180427\n"
          ]
        }
      ],
      "source": [
        "#knn\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Read the CSV file\n",
        "file_path = \"/content/data.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['Type']\n",
        "\n",
        "# Normalize the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Optional: Dimensionality Reduction using PCA\n",
        "pca = PCA(n_components=10)  # Adjust n_components as needed\n",
        "X_pca = pca.fit_transform(X_normalized)\n",
        "\n",
        "# Set a fixed random state\n",
        "random_state = 543\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Initialize a k-NN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "# Use GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best estimator\n",
        "best_knn = grid_search.best_estimator_\n",
        "\n",
        "# Train the classifier with the best parameters on the training data\n",
        "best_knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred = best_knn.predict(X_test)\n",
        "\n",
        "# Calculate the performance metrics for the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "\n",
        "# Print the performance metrics and the best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2cBrWzcUeYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b382186f-0486-4178-bab6-b189ae7f9057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'}\n",
            "Accuracy: 0.996551724137931\n",
            "Precision: 0.9966250917094643\n",
            "Recall: 0.996551724137931\n",
            "F1-score: 0.9965459796226375\n"
          ]
        }
      ],
      "source": [
        "#knn with daa\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Read the CSV file\n",
        "file_path = \"/content/augmented2.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['Type']\n",
        "\n",
        "# Normalize the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Optional: Dimensionality Reduction using PCA\n",
        "pca = PCA(n_components=10)  # Adjust n_components as needed\n",
        "X_pca = pca.fit_transform(X_normalized)\n",
        "\n",
        "# Set a fixed random state\n",
        "random_state = 29\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "# Initialize a k-NN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "}\n",
        "\n",
        "# Use GridSearchCV to find the best hyperparameters\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best estimator\n",
        "best_knn = grid_search.best_estimator_\n",
        "\n",
        "# Train the classifier with the best parameters on the training data\n",
        "best_knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred = best_knn.predict(X_test)\n",
        "\n",
        "# Calculate the performance metrics for the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "\n",
        "# Print the performance metrics and the best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}